{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e9eeef; border-right: 10px solid #36b38d ;\" height=300 width=100%>\n",
    "    <font color=#2b3444 size=8 align=left ><strong> Revenue Forecasting</strong></font><br>\n",
    "    <font color=#36b38d size=6 align=left ><strong> Model Training Interface</strong></font>\n",
    "</div>\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from ipywidgets import FileUpload\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# import xgboost as xgb\n",
    "# from math import sqrt\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from scipy.stats import uniform, randint\n",
    "# from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import pydot_ng as pydot\n",
    "# from IPython.display import Image\n",
    "# import math\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "# import sys\n",
    "# import io\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model \n",
    "**Predictions can be generated using two models - XGBoost and FBprophet. This dashboard only hosts the XGBoost Model.**\n",
    "\n",
    "**Steps to use the dashboard are listed below**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "## Steps to Generate Predictions\n",
    "### - Select Pre existing or re-train a new model\n",
    "**You can choose to generate predictions with the existing model. Or you can choose to re-train the model with a new dataset.**\n",
    "\n",
    "**For Existing Model: Each prediction cycle takes a single .csv test file and latest version of PD Sync.The test file MUST contain the month and year columns. If you would like to predict for multiple months, please combine all the months into a single file or predict for one month at a time.**\n",
    "\n",
    "**For example if you would like to generate predictions for 2 months - Nov and Dec. You can either combine the data for both the months in a single file or upload two separate files containing data for Nov and Dec respectively.**\n",
    "\n",
    "**For Re-training: Each prediction cycle takes three files, pd sync, revenue projection and a test file, all three files can be .csv or .xlsx in format. PD Sync and Revenue Projection files are combined to create the training data and the test file is used to generate predictions based on the newly trained model.**\n",
    "\n",
    "\n",
    "### - Select level of training / testing\n",
    "**What are Levels?**\n",
    "\n",
    "**There are 3 levels within which the model can generate predictions. These are - L0, L1 and L2.**\n",
    "\n",
    "**L0 - For predictions at Quantiphi level**\n",
    "\n",
    "**L1 - For predictions at Channel vs. BU level**\n",
    "\n",
    "**L2 - For further predictions within a Channel and BU.** \n",
    "**In channels, only GCP has been considered for predictions due to sufficient data volume. Within GCP predictions can be made for different regions and practices.**\n",
    "\n",
    "**IN BUs, only BFSI has been considered for predictions due to sufficient data volumne. Within BFSI, predictions can be made for deals that are in AWS, GCP or Direct**\n",
    "\n",
    "### - Format and Predict\n",
    "**This stage is where all the uploaded files are formatted according to the level selected and then fed into the model.**\n",
    "\n",
    "**The model along with the rest of the code runs in the backend and generates predictions.**\n",
    "\n",
    "**Apart from predictions, the model also outputs performance metrics such as MAE (mean absolute error) and MAPE (mean absolute percentage error).**\n",
    "\n",
    "**Predicted data and metrics are also available for download.**\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Important points before uploading data</font>\n",
    "**For pre-existing data, two files are required - latest PD Sync and a test file**\n",
    "* Test file should contain only the following columns with the exact spelling & format - Year , Month ,\tDeal ID\t, Weights , \tStages , Leads UW , Business Unit , Channel\n",
    "* PD Sync file can contain any no. of columns\n",
    "\n",
    "**For re-training data, three files are required - latest PD Sync and a test file**\n",
    "* Test file should contain only the following columns with the exact spelling & format - Year , Month ,\tDeal ID\t, Weights , \tStages , Leads UW , Business Unit , Channel\n",
    "* PD Sync file and Revenue projection file can contain any no. of columns\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50eec50cc084a20af634e06509d61bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<b><font size=4>Select prediction method</b>'), RadioButtons(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "output_box = widgets.Output()\n",
    "\n",
    "dataset_selector = widgets.RadioButtons(\n",
    "    options=['Predict with existing model', 'Re-train model'],\n",
    "    description='Select: ',\n",
    "    disabled=False\n",
    ")\n",
    "        \n",
    "#######---------------------------------------UPLOADER FUNCTION FOR PRE-EXISTING DATA-----------------------------------########\n",
    "\n",
    "#Uploader function for pd sync test\n",
    "label_pdsync_test=widgets.Label('Please upload PD Sync file in .csv or .xlsx format. Please click the Next button after Upload changes from 0 to 1')\n",
    "uploader_pdsync_test = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_pdsync_test_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "\n",
    "def get_pdsync_test(b):\n",
    "    input_file = list(uploader_pdsync_test.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_pdsync_test = pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_pdsync_test = pd.read_excel(content)    \n",
    "\n",
    "#     display(df_pdsync_test)\n",
    "    get_pdsync_test.data = df_pdsync_test\n",
    "    \n",
    "label_test=widgets.Label('Please upload the test file in .xlsx or .csv format. Please click the Next button after Upload changes from 0 to 1')\n",
    "uploader_test = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_test_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "#Uploader function for test data\n",
    "def get_test(b):\n",
    "    input_file = list(uploader_test.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_test = pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_test = pd.read_excel(content)    \n",
    "\n",
    "#     display(df_test) \n",
    "    get_test.data = df_test\n",
    "#########--------------------------------------------L1 SELECTOR & FORMATTER FOR EXISTING----------------------------------------------------########    \n",
    "B = widgets.Button(\n",
    "     description='Format Data',\n",
    "     disabled=False,\n",
    "     button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "     tooltip='Click me',\n",
    "     icon='run'\n",
    ")\n",
    "text9 = 'L1 Level Selected - GCP'\n",
    "l1selectgcp = widgets.HTML(value = f\"<b><font color='#36b38d' size=3>{text9}</b>\")\n",
    "textaws1 = 'L1 Level Selected - AWS'\n",
    "l1selectaws = widgets.HTML(value = f\"<b><font color='#36b38d' size=3>{textaws1}</b>\")\n",
    "textbfsi1 = 'L1 Level Selected - BFSI'\n",
    "l1selectbfsi = widgets.HTML(value = f\"<b><font color='#36b38d' size=3>{textbfsi1}</b>\")\n",
    "texthcls1 = 'L1 Level Selected - HCLS'\n",
    "l1selecthcls = widgets.HTML(value = f\"<b><font color='#36b38d' size=3>{texthcls1}</b>\")\n",
    "texttmeg1 = 'L1 Level Selected - TMEG'\n",
    "l1selecttmeg = widgets.HTML(value = f\"<b><font color='#36b38d' size=3>{texttmeg1}</b>\")\n",
    "def on_change_l1(change):\n",
    "    with output_box:\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            if change['new'] == 'GCP':\n",
    "                with output_box:\n",
    "                    display(l1selectgcp)\n",
    "                    time.sleep(10)\n",
    "                    l1_format_test_gcp()         \n",
    "            elif change['new'] == 'BFSI':\n",
    "                with output_box:\n",
    "                    display(l1selectbfsi)\n",
    "                    time.sleep(10)\n",
    "                    l1_format_test_bfsi()\n",
    "            elif change['new'] == 'AWS':\n",
    "                with output_box:\n",
    "                    display(l1selectaws)\n",
    "                    time.sleep(10)\n",
    "                    l1_format_test_aws()\n",
    "            elif change['new'] == 'TMEG':\n",
    "                with output_box:\n",
    "                    display(l1selecttmeg)\n",
    "                    time.sleep(10)\n",
    "                    l1_format_test_tmeg()\n",
    "            elif change['new'] == 'HCLS':\n",
    "                with output_box:\n",
    "                    display(l1selecthcls)\n",
    "                    time.sleep(10)\n",
    "                    l1_format_test_()\n",
    "#########--------------------------------------------L2 SELECTOR & FORMATTER EXISTING----------------------------------------------------########\n",
    "l2selectgcpue = widgets.HTML(value = f\"<b><font color='#36b38d' size=3>{textgcpue1}</b>\")\n",
    "textgcpue1 = 'L2 Level Selected - GCP US-East'\n",
    "def on_change_l2(change):\n",
    "    with output_box:\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            if change['new'] == 'GCP-US-East':\n",
    "                with output_box:\n",
    "#                     display(l2selectgcpue)\n",
    "#                     time.sleep(10)\n",
    "#                     l1_format_test_gcp()\n",
    "                      print('GCP-US-East Region Selected')\n",
    "                      display(B)\n",
    "            elif change['new'] == 'GCP-US-West':\n",
    "                with output_box:\n",
    "                    print('GCP-US-West Region Selected')\n",
    "                    display(B)\n",
    "            elif change['new'] == 'GCP-US-Central':\n",
    "                with output_box:\n",
    "                    print('GCP-US-Central Region Selected')\n",
    "                    display(B)        \n",
    "            elif change['new'] == 'BFSI-AWS':\n",
    "                with output_box:\n",
    "                    print('BFSI-AWS Selected') \n",
    "                    display(B)\n",
    "            elif change['new'] == 'BFSI-Direct':\n",
    "                with output_box:\n",
    "                    print('BFSI-Direct Selected')\n",
    "                    display(B)\n",
    "            elif change['new'] == 'BFSI-GCP':\n",
    "                with output_box:\n",
    "                    print('BFSI-GCP Selected')   \n",
    "                    display(B)\n",
    "#########--------------------------------------------LEVEL SELECTOR EXISTING----------------------------------------------------########\n",
    "\n",
    "level_selector = widgets.RadioButtons(\n",
    "                         options=['L0','L1','L2'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    "#     layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "level1_selector = widgets.RadioButtons(\n",
    "                         options=['GCP','AWS','BFSI', 'TMEG', 'HCLS'],\n",
    "                         value=None,\n",
    "                         description='Select Channel/BU: ',\n",
    "                         disabled=False,\n",
    "                         layout=widgets.Layout(width='100%'),\n",
    "                         align_items='stretch',\n",
    "                         style= {'description_width': 'initial'}\n",
    "    \n",
    ")\n",
    "\n",
    "level2_selector = widgets.RadioButtons(\n",
    "                         options=['BFSI-AWS', 'BFSI-Direct', 'BFSI-GCP', 'GCP-US-Central','GCP-US-East','GCP-US-West'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "lev_button = widgets.Button(\n",
    "description='Format Data',\n",
    "disabled=False,\n",
    "button_style='info', \n",
    "tooltip='Run'\n",
    "    # #     icon='play'\n",
    ")\n",
    "\n",
    "label_level = widgets.Label('Please select level for prediction')\n",
    "\n",
    "def selectlevel(button):\n",
    "    with output_box:\n",
    "        selection = level_selector.get_interact_value()\n",
    "        if (selection == \"L0\"):\n",
    "            with output_box:\n",
    "                display(l0select)\n",
    "                time.sleep(10)\n",
    "                l0_format_test()               \n",
    "        elif (selection ==\"L1\"):\n",
    "            with output_box:\n",
    "                level1_selector.observe(on_change_l1)\n",
    "                display(level1_selector)\n",
    "\n",
    "        elif (selection ==\"L2\"):\n",
    "            with output_box:\n",
    "                print('L2 Level Selected')\n",
    "                level2_selector.observe(on_change_l2)\n",
    "                display(level2_selector)    \n",
    "\n",
    "l0_button = widgets.Button(\n",
    "     description='Format Data',\n",
    "     disabled=False,\n",
    "     button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "     tooltip='Click me',\n",
    "     icon='run'\n",
    ")\n",
    "\n",
    "def lessthanzero(x):\n",
    "    return x <= 0 \n",
    "#########--------------------------------------------L1 FORMATTING TESTING EXISTING GCP-------------------------------------########\n",
    "l1_predict_gcp_button= widgets.Button(description='Predict',button_style='info',tooltip='Run')\n",
    "text8 = 'Running Predictions for GCP L1'\n",
    "predictionl1gcp_Widget = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{text8}</b>\")\n",
    "\n",
    "def create_download_link_l1_gcp( df, title = \"Download formatted test CSV file for GCP L1\", filename = \"formatted-data-GCP-L1.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l1_gcp_final( df, title = \"Download GCP L1 prediction CSV file\", filename = \"prediction-L1-GCP.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def l1_format_test_gcp():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_test = get_test.data\n",
    "    df_pdsync_test = get_pdsync_test.data\n",
    "    df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_test = df_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df_test.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'industry','Channel',\n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    df_all = df_all.loc[(df_all['Channel'] == 'GCP')]\n",
    "    df_all = df_all.drop(columns=['Channel'])\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "      'dealid',\n",
    "#       'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#     #  'Practice',\n",
    "#     #  'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#     #  'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "    result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "    result = result.rename(columns={\"region\": \"Region\"})\n",
    "    result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    test = result.drop(columns=['dealid'])\n",
    "    test = test[['Weight', 'dealvalue', 'Leads UW', 'Stage', 'Region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    display('Displaying formatted file below: ')\n",
    "    display(test)\n",
    "    display(create_download_link_l1_gcp(test))\n",
    "    display(predictionl1gcp_Widget)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    month = df_test['Month'].iloc[1]\n",
    "    year = df_test['Year'].iloc[1]\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    pred = l1_predict_gcp(test)\n",
    "    display(HTML('<strong>{}</strong><br>'.format(pred))   )\n",
    "    df_l1_gcp = pd.DataFrame(data = [[month,year,pred,'nan','nan','nan']], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l1_gcp_final(df_l1_gcp))\n",
    "\n",
    "def l1_model_gcp():\n",
    "    with open('./xgb_L1_gcp.pkl', 'rb') as f:\n",
    "        l1_model_gcp = pickle.load(f)\n",
    "    return l1_model_gcp\n",
    "\n",
    "def l1_predict_gcp(df):\n",
    "         # Feature arragend as per the model\n",
    "    model_l1_gcp=l1_model_gcp()\n",
    "    predict_l1_gcp = model_l1_gcp.predict(df)               # Prediction using the model\n",
    "    prediction_l1_gcp = np.sum(predict_l1_gcp, dtype=np.int32)      # Predicted result is made into readable format\n",
    "    return prediction_l1_gcp\n",
    "\n",
    "#########--------------------------------------------L1 FORMATTING TESTING EXISTING AWS-------------------------------------########\n",
    "l1_predict_aws_button= widgets.Button(description='Predict',button_style='info',tooltip='Run')\n",
    "textaws2 = 'Running Predictions for AWS L1'\n",
    "predictionl1aws_Widget = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{textaws2}</b>\")\n",
    "\n",
    "def create_download_link_l1_aws( df, title = \"Download formatted test CSV file for AWS L1\", filename = \"formatted-data-AWS-L1.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l1_aws_final( df, title = \"Download AWS L1 prediction CSV file\", filename = \"prediction-L1-AWS.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def l1_format_test_aws():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_test = get_test.data\n",
    "    df_pdsync_test = get_pdsync_test.data\n",
    "    df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_test = df_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df_test.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'industry','Channel',\n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact','sourceoflead','Business Category1']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    df_all = df_all.loc[(df_all['Channel'] == 'AWS')]\n",
    "    df_all = df_all.drop(columns=['Channel'])\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact','Business Category1', 'sourceoflead']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "      'dealid',\n",
    "#       'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#       'Practice',\n",
    "      'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "       'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "    result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "    result = result.rename(columns={\"region\": \"Region\"})\n",
    "    result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    test = result.drop(columns=['dealid'])\n",
    "    test = test[['Weight', 'dealvalue', 'Leads UW', 'Stage', 'Region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact','Business Category1','sourceoflead']]\n",
    "    test = scale.transform(test)\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    display('Displaying formatted file below: ')\n",
    "    display(test)\n",
    "    display(create_download_link_l1_aws(test))\n",
    "    display(predictionl1aws_Widget)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    month = df_test['Month'].iloc[1]\n",
    "    year = df_test['Year'].iloc[1]\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    pred = l1_predict_aws(test)\n",
    "    display(HTML('<strong>{}</strong><br>'.format(pred))   )\n",
    "    df_l1_aws = pd.DataFrame(data = [[month,year,pred,'nan','nan','nan']], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l1_aws_final(df_l1_aws))\n",
    "\n",
    "def l1_model_aws():\n",
    "    with open('./xgb_L1_aws.pkl', 'rb') as f:\n",
    "        l1_model_aws = pickle.load(f)\n",
    "    return l1_model_aws\n",
    "\n",
    "def l1_predict_aws(df):\n",
    "         # Feature arragend as per the model\n",
    "    model_l1_aws=l1_model_aws()\n",
    "    predict_l1_aws = model_l1_aws.predict(df)               # Prediction using the model\n",
    "    prediction_l1_aws = np.sum(predict_l1_aws, dtype=np.int32)      # Predicted result is made into readable format\n",
    "    return prediction_l1_aws\n",
    "\n",
    "#########--------------------------------------------L1 FORMATTING TESTING EXISTING BFSI-------------------------------------########\n",
    "l1_predict_bfsi_button= widgets.Button(description='Predict',button_style='info',tooltip='Run')\n",
    "textbfsi2 = 'Running Predictions for BFSI L1'\n",
    "predictionl1bfsi_Widget = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{textbfsi2}</b>\")\n",
    "\n",
    "def create_download_link_l1_bfsi( df, title = \"Download formatted test CSV file for BFSI L1\", filename = \"formatted-data-BFSI-L1.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l1_bfsi_final( df, title = \"Download BFSI L1 prediction CSV file\", filename = \"prediction-L1-BFSI.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def l1_format_test_bfsi():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_test = get_test.data\n",
    "    df_pdsync_test = get_pdsync_test.data\n",
    "    df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_test = df_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df_test.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'dealvalue', 'Stages',\n",
    "       'Weights', 'region','Business Unit', 'industry',\n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact',\n",
    "       'projectduration']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    df_all = df_all.loc[(df_all['Business Unit'] == 'BFSI')]\n",
    "    df_all = df_all.drop(columns=['Business Unit'])\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "      'dealid',\n",
    "#       'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#       'Practice',\n",
    "#       'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#        'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "    result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "    result = result.rename(columns={\"region\": \"Region\"})\n",
    "    result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    test = result.drop(columns=['dealid'])\n",
    "    test = test[['Weight', 'dealvalue', 'Leads UW', 'Stage', 'Region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     test = scale.transform(test)\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    display('Displaying formatted file below: ')\n",
    "    display(test)\n",
    "    display(create_download_link_l1_bfsi(test))\n",
    "    display(predictionl1bfsi_Widget)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    month = df_test['Month'].iloc[1]\n",
    "    year = df_test['Year'].iloc[1]\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    pred = l1_predict_bfsi(test)\n",
    "    display(HTML('<strong>{}</strong><br>'.format(pred))   )\n",
    "    df_l1_bfsi = pd.DataFrame(data = [[month,year,pred,'nan','nan','nan']], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l1_bfsi_final(df_l1_bfsi))\n",
    "\n",
    "def l1_model_bfsi():\n",
    "    with open('./xgb_L1_bfsi.pkl', 'rb') as f:\n",
    "        l1_model_bfsi = pickle.load(f)\n",
    "    return l1_model_bfsi\n",
    "\n",
    "def l1_predict_bfsi(df):\n",
    "         # Feature arragend as per the model\n",
    "    model_l1_bfsi=l1_model_bfsi()\n",
    "    predict_l1_bfsi = model_l1_bfsi.predict(df)               # Prediction using the model\n",
    "    prediction_l1_bfsi = np.sum(predict_l1_bfsi, dtype=np.int32)      # Predicted result is made into readable format\n",
    "    return prediction_l1_bfsi\n",
    "\n",
    "\n",
    "#########--------------------------------------------L1 FORMATTING TESTING EXISTING HCLS-------------------------------------########\n",
    "l1_predict_hcls_button= widgets.Button(description='Predict',button_style='info',tooltip='Run')\n",
    "texthcls2 = 'Running Predictions for HCLS L1'\n",
    "predictionl1hcls_Widget = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{texthcls2}</b>\")\n",
    "\n",
    "def create_download_link_l1_hcls( df, title = \"Download formatted test CSV file for HCLS L1\", filename = \"formatted-data-HCLS-L1.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l1_hcls_final( df, title = \"Download HCLS L1 prediction CSV file\", filename = \"prediction-L1-HCLS.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def l1_format_test_hcls():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_test = get_test.data\n",
    "    df_pdsync_test = get_pdsync_test.data\n",
    "    df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_test = df_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df_test.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'dealvalue', 'Stages',\n",
    "       'Weights', 'region','Business Unit', 'industry',\n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact',\n",
    "       'projectduration']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    df_all = df_all.loc[(df_all['Business Unit'] == 'HCLS')]\n",
    "    df_all = df_all.drop(columns=['Business Unit'])\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "      'dealid',\n",
    "#       'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#       'Practice',\n",
    "#       'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#        'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "    result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "    result = result.rename(columns={\"region\": \"Region\"})\n",
    "    result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    test = result.drop(columns=['dealid'])\n",
    "    test = test[['Weight', 'dealvalue', 'Leads UW', 'Stage', 'Region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     test = scale.transform(test)\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    display('Displaying formatted file below: ')\n",
    "    display(test)\n",
    "    display(create_download_link_l1_hcls(test))\n",
    "    display(predictionl1hcls_Widget)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    month = df_test['Month'].iloc[1]\n",
    "    year = df_test['Year'].iloc[1]\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    pred  = l1_predict_hcls(test)\n",
    "    display(HTML('<strong>{}</strong><br>'.format(pred))   )\n",
    "    df_l1_hcls = pd.DataFrame(data = [[month,year,pred,'nan','nan','nan']], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l1_hcls_final(df_l1_hcls))\n",
    "\n",
    "def l1_model_hcls():\n",
    "    with open('./xgb_L1_hcls.pkl', 'rb') as f:\n",
    "        l1_model_hcls = pickle.load(f)\n",
    "    return l1_model_hcls\n",
    "\n",
    "def l1_predict_hcls(df):\n",
    "         # Feature arragend as per the model\n",
    "    model_l1_hcls=l1_model_hcls()\n",
    "    predict_l1_hcls = model_l1_hcls.predict(df)               # Prediction using the model\n",
    "    prediction_l1_hcls = np.sum(predict_l1_hcls, dtype=np.int32)      # Predicted result is made into readable format\n",
    "    return prediction_l1_hcls\n",
    "\n",
    "#########--------------------------------------------L1 FORMATTING TESTING EXISTING TMEG-------------------------------------########\n",
    "l1_predict_tmeg_button= widgets.Button(description='Predict',button_style='info',tooltip='Run')\n",
    "texttmeg2 = 'Running Predictions for TMEG L1'\n",
    "predictionl1tmeg_Widget = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{texttmeg2}</b>\")\n",
    "\n",
    "def create_download_link_l1_tmeg( df, title = \"Download formatted test CSV file for TMEG L1\", filename = \"formatted-data-TMEG-L1.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l1_tmeg_final( df, title = \"Download TMEG L1 prediction CSV file\", filename = \"prediction-L1-TMEG.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def l1_format_test_tmeg():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_test = get_test.data\n",
    "    df_pdsync_test = get_pdsync_test.data\n",
    "    df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_test = df_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df_test.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'Business Unit', 'industry',\n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact',\n",
    "       'sourceoflead', 'Business Category1']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    df_all = df_all.loc[(df_all['Business Unit'] == 'TMEG')]\n",
    "    df_all = df_all.drop(columns=['Business Unit'])\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact', 'sourceoflead', 'Business Category1']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "                 'dealid',\n",
    "#   'Actuals',\n",
    "  'Weights',\n",
    "  'Leads UW',\n",
    " 'dealvalue',\n",
    " 'Stages',\n",
    "#  'PSO/Non-PSO',\n",
    "  'region',\n",
    "#   'Practice',\n",
    "  'sourceoflead',\n",
    "  'industry',\n",
    "  'billingtype',\n",
    "  'solcategory',\n",
    "  'Business Category1',\n",
    "  'projectType',\n",
    "  #  'projectextension',\n",
    "   'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "    result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "    result = result.rename(columns={\"region\": \"Region\"})\n",
    "    result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    test = result.drop(columns=['dealid'])\n",
    "    test = test[['Weight', 'dealvalue', 'Leads UW', 'Stage', 'Region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact','Business Category1','sourceoflead']]\n",
    "    test = scale.fit_transform(test)\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    display('Displaying formatted file below: ')\n",
    "    display(test)\n",
    "    display(create_download_link_l1_tmeg(test))\n",
    "    display(predictionl1tmeg_Widget)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    month = df_test['Month'].iloc[1]\n",
    "    year = df_test['Year'].iloc[1]\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    pred = l1_predict_tmeg(test)\n",
    "    display(HTML('<strong>{}</strong><br>'.format(pred))   )\n",
    "    df_l1_tmeg = pd.DataFrame(data = [[month,year,pred,'nan','nan','nan']], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l1_tmeg_final(df_l1_tmeg))\n",
    "\n",
    "def l1_model_tmeg():\n",
    "    with open('./xgb_L1_tmeg.pkl', 'rb') as f:\n",
    "        l1_model_tmeg = pickle.load(f)\n",
    "    return l1_model_tmeg\n",
    "\n",
    "def l1_predict_tmeg(df):\n",
    "         # Feature arragend as per the model\n",
    "    model_l1_tmeg=l1_model_tmeg()\n",
    "    predict_l1_tmeg = model_l1_tmeg.predict(df)               # Prediction using the model\n",
    "    prediction_l1_tmeg = np.sum(predict_l1_tmeg, dtype=np.int32)      # Predicted result is made into readable format\n",
    "    return prediction_l1_tmeg\n",
    "\n",
    "\n",
    "#########--------------------------------------------L2 FORMATTING TESTING EXISTING GCP US-EAST-------------------------------------########\n",
    "# l2_predict_gcpue_button= widgets.Button(description='Predict',button_style='info',tooltip='Run')\n",
    "# text8 = 'Running Predictions for L2 - GCP US-East'\n",
    "# predictionl2gcpue_Widget = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{text8}</b>\")\n",
    "\n",
    "# def create_download_link_l2_gcpue( df, title = \"Download formatted test CSV file for L2 GCP US-East\", filename = \"formatted-data-GCP-L2-USEast.csv\"):\n",
    "#     csv = df.to_csv(index=False)\n",
    "#     b64 = base64.b64encode(csv.encode())\n",
    "#     payload = b64.decode()\n",
    "#     html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "#     html = html.format(payload=payload,title=title,filename=filename)\n",
    "#     return HTML(html)\n",
    "\n",
    "# def create_download_link_l2_gcpue_final( df, title = \"Download L2 GCP US-East prediction CSV file\", filename = \"prediction-GCP-L2-USEast.csv\"):\n",
    "#     csv = df.to_csv(index=False)\n",
    "#     b64 = base64.b64encode(csv.encode())\n",
    "#     payload = b64.decode()\n",
    "#     html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "#     html = html.format(payload=payload,title=title,filename=filename)\n",
    "#     return HTML(html)\n",
    "\n",
    "# def l2_format_test_gcp_ue():\n",
    "# #     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "#     df_test = get_test.data\n",
    "#     df_pdsync_test = get_pdsync_test.data\n",
    "#     df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "#     df_test = df_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "#     df_all = df_test.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "#                     how='left', indicator=True)\n",
    "#     df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "#     dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "#     df_all = df_all[~dropstage]\n",
    "#     df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'dealvalue', 'Stages',\n",
    "#        'Weights', 'region', 'industry','Channel',\n",
    "#        'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "#     df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "#     df_all = df_all.loc[(df_all['Channel'] == 'GCP')]\n",
    "#     df_all = df_all.loc[(df_all['region'] == 'US-East')]\n",
    "#     df_all = df_all.drop(columns=['Channel', 'region'])\n",
    "#     cols2 = ['Stages', 'industry',\n",
    "#         'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "#     df_all[cols2] = df_all[cols2].astype(str)\n",
    "#     label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "#     cols1 = df_all.select_dtypes([np.number]).columns\n",
    "#     numerical = df_all[cols1]\n",
    "#     numerical['tmp'] = 1\n",
    "#     label_encode_columns['tmp'] = 1\n",
    "#     result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "#     result = result.drop(columns=['tmp'])\n",
    "#     result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "#     result = result.drop(columns=['Year','Month'])\n",
    "#     result = result[['Date',\n",
    "#       'dealid',\n",
    "# #       'Actuals',\n",
    "#       'Weights',\n",
    "#       'Leads UW',\n",
    "#      'dealvalue',\n",
    "#      'Stages',\n",
    "# #     #  'PSO/Non-PSO',\n",
    "#       'region',\n",
    "# #     #  'Practice',\n",
    "# #     #  'sourceoflead',\n",
    "#        'industry',\n",
    "#        'billingtype',\n",
    "#        'solcategory',\n",
    "# #     #  'Business Category1',\n",
    "#        'projectType',\n",
    "# #     #  'projectextension',\n",
    "#        'businessimpact',\n",
    "#     ]]                                \n",
    "                                     \n",
    "#     result['Date'] = pd.to_datetime(result['Date'])\n",
    "#     result = result.set_index(result['Date'])\n",
    "#     result = result.sort_index()\n",
    "#     result = result.drop(columns=['Date'])\n",
    "#     result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "#     result = result.rename(columns={\"region\": \"Region\"})\n",
    "#     result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "#     test = result.drop(columns=['dealid'])\n",
    "#     test = test[['Weight', 'dealvalue', 'Leads UW', 'Stage', 'Region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     test = scale.transform(test)\n",
    "# # test = test.apply(pd.to_numeric)\n",
    "#     display('Displaying formatted file below: ')\n",
    "#     display(test)\n",
    "#     display(create_download_link_l2_gcpue(test))\n",
    "#     display(predictionl2gcpue_Widget)\n",
    "#     display(\"Predicting.Please Wait..\")\n",
    "#     time.sleep(10)\n",
    "#     display(\"Predicting.Please Wait..\")\n",
    "#     time.sleep(10)\n",
    "#     display(\"Predicting.Please Wait..\")\n",
    "#     time.sleep(10)\n",
    "#     month = df_test['Month'].iloc[1]\n",
    "#     year = df_test['Year'].iloc[1]\n",
    "#     print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "#     pred = l2_predict_gcpue(test)\n",
    "#     display(HTML('<strong>{}</strong><br>'.format(pred))   )\n",
    "#     df_l2_gcpue = pd.DataFrame(data = [[month,year,pred,'nan','nan','nan']], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "#     display(create_download_link_l2_gcpue_final(df_l1_gcpue))\n",
    "\n",
    "# def l2_model_gcpue():\n",
    "#     with open('./xgb_L1_gcp.pkl', 'rb') as f:\n",
    "#         l2_model_gcpue = pickle.load(f)\n",
    "#     return l1_model_gcpue\n",
    "\n",
    "# def l2_predict_gcpue(df):\n",
    "#          # Feature arragend as per the model\n",
    "#     model_l2_gcpue=l2_model_gcpue()\n",
    "#     predict_l2_gcpue = model_l2_gcpue.predict(df)               # Prediction using the model\n",
    "#     prediction_l2_gcpue = np.sum(predict_l2_gcp,ue dtype=np.int32)      # Predicted result is made into readable format\n",
    "#     return prediction_l2_gcpue\n",
    "\n",
    "#########--------------------------------------------L0 FORMATTING TESTING EXISTING-------------------------------------########\n",
    "l0_predict_button= widgets.Button(description='Predict',button_style='info',tooltip='Run')\n",
    "text = 'Running Predictions for L0'\n",
    "predictionl0_Widget = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{text}</b>\")\n",
    "\n",
    "def create_download_link_l0( df, title = \"Download formatted test CSV file\", filename = \"formatted-data.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l0_final( df, title = \"Download L0 prediction CSV file\", filename = \"prediction-L0.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def l0_format_test():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_test = get_test.data\n",
    "    df_pdsync_test = get_pdsync_test.data\n",
    "    df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_test = df_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df_test.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'industry',\n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "      'dealid',\n",
    "#       'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#     #  'Practice',\n",
    "#     #  'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#     #  'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "    result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "    result = result.rename(columns={\"region\": \"Region\"})\n",
    "    result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    test = result.drop(columns=['dealid'])\n",
    "    test = test[['Weight', 'dealvalue', 'Leads UW', 'Stage', 'Region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    display('Displaying formatted file below: ')\n",
    "    display(test)\n",
    "    display(create_download_link_l0(test))\n",
    "    display(predictionl0_Widget)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    month = df_test['Month'].iloc[1]\n",
    "    year = df_test['Year'].iloc[1]\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    \n",
    "    pred = l0_predict(test)\n",
    "    display(HTML('<strong>{}</strong><br>'.format(pred))   )\n",
    "    df_l0 = pd.DataFrame(data = [[month,year,pred,'nan','nan','nan']], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l0_final(df_l0))\n",
    "    \n",
    "######--------------------------------------------L0 MODEL LOAD TESTING---------------------------------------------------------########    \n",
    "\n",
    "def l0_model():\n",
    "    with open('./xgb_L0.pkl', 'rb') as f:\n",
    "        l0_model = pickle.load(f)\n",
    "    return l0_model\n",
    "\n",
    "def l0_predict(df):\n",
    "         # Feature arragend as per the model\n",
    "    model_l0=l0_model()\n",
    "    predict_l0 = model_l0.predict(df)               # Prediction using the model\n",
    "    prediction = np.sum(predict_l0, dtype=np.int32)      # Predicted result is made into readable format\n",
    "    return prediction\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#######-------------------------------------UPLOADER FUNCTION FOR RE-TRAINING DATA--------------------------------------########\n",
    "\n",
    "#Uploader function for pd sync test\n",
    "label_pdsync_rt=widgets.Label('Please upload PD Sync file in .csv or .xlsx format. Please click the Next button after Upload changes from 0 to 1')\n",
    "uploader_pdsync_rt = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_pdsync_rt_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "\n",
    "def get_pdsync_rt(b):\n",
    "    input_file = list(uploader_pdsync_rt.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_pdsync_rt = pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_pdsync_rt = pd.read_excel(content)    \n",
    "\n",
    "#     display(df_pdsync_rt)\n",
    "    get_pdsync_rt.data = df_pdsync_rt\n",
    "    \n",
    "    \n",
    "label_rp=widgets.Label('Please upload the latest rev projections sheet in .xlsx or .csv format. Please click the Next button after Upload changes from 0 to 1')\n",
    "uploader_rp = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_rp_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "#Uploader function for test data\n",
    "def get_rp(b):\n",
    "    input_file = list(uploader_rp.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_rp= pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_rp = pd.read_excel(content)    \n",
    "\n",
    "#     display(df_rp) \n",
    "    get_rp.data = df_rp\n",
    "label_test_rt=widgets.Label('Please upload the test sheet for which you want to test the re-trained model in .xlsx or .csv format. Please click the Next button after Upload changes from 0 to 1')\n",
    "uploader_test_rt = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_rt_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "#Uploader function for test data\n",
    "def get_test_rt(b):\n",
    "    input_file = list(uploader_test_rt.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_rt= pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_rt = pd.read_excel(content)    \n",
    "#     display(df_rt)\n",
    "    get_test_rt.data = df_rt\n",
    "    \n",
    "#######----------------------------------------LEVEL SELECTOR RE-TRAIN----------------------------------------------############\n",
    "level_selector_rt = widgets.RadioButtons(\n",
    "                         options=['L0','L1','L2'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    "#     layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "level1_selector_rt = widgets.RadioButtons(\n",
    "                         options=['GCP','AWS','BFSI', 'TMEG', 'HCLS'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    "#     layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "level2_selector_rt = widgets.RadioButtons(\n",
    "                         options=['BFSI-AWS', 'BFSI-Direct', 'BFSI-GCP', 'GCP-US-Central','GCP-US-East','GCP-US-West'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "lev_button_rt = widgets.Button(\n",
    "description='Format Data',\n",
    "disabled=False,\n",
    "button_style='info', \n",
    "tooltip='Run'\n",
    "    # #     icon='play'\n",
    ")\n",
    "\n",
    "label_level_rt = widgets.Label('Please select level for prediction')\n",
    "# l0label = widgets.Label('L0 Level Selected')\n",
    "text1 = 'L0 Level Selected'\n",
    "l0select = widgets.HTML(value = f\"<b><font color='#36b38d' size=3>{text1}</b>\")\n",
    "\n",
    "\n",
    "# l0start = widgets.Button(\n",
    "# description='Next',\n",
    "# disabled=False,\n",
    "# button_style='info', \n",
    "# tooltip='Run'\n",
    "#     # #     icon='play'\n",
    "# )\n",
    "def selectlevel_rt(button):\n",
    "    with output_box:\n",
    "        selection = level_selector_rt.get_interact_value()\n",
    "        if (selection == \"L0\"):\n",
    "            with output_box:\n",
    "                display(l0select)\n",
    "                time.sleep(10)\n",
    "                l0_format_rt()                       \n",
    "        elif (selection ==\"L1\"):\n",
    "            with output_box:\n",
    "                 print('L1 Level Selected')\n",
    "#                  level1_selector_rt.observe(on_change_l1_rt)\n",
    "#                  display(level1_selector_rt)\n",
    "\n",
    "        elif (selection ==\"L2\"):\n",
    "            with output_box:\n",
    "                print('L2 Level Selected')\n",
    "#                 level2_selector_rt.observe(on_change_l2_rt)\n",
    "#                 display(level2_selector_rt)    \n",
    "\n",
    "l0_button_rt = widgets.Button(\n",
    "     description='Format Data',\n",
    "     disabled=False,\n",
    "     button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "     tooltip='Click me',\n",
    "     icon='run'\n",
    ")\n",
    "\n",
    "#########-------------------------------------------L0 FORMATTER RE-TRAIN------------------------------------------#############\n",
    "def create_download_link_l0_train( df, title = \"Download formatted training CSV file\", filename = \"formatted-data.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l0_test( df, title = \"Download formatted test CSV file\", filename = \"formatted-data.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l0_rt_final( df, title = \"Download L0 prediction CSV file\", filename = \"prediction-L0-RT.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "\n",
    "def l0_format_rt():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_pdsync_rt = get_pdsync_rt.data\n",
    "    df_pdsync_rt = df_pdsync_rt[['dealid', 'dealvalue','industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    df_rp = get_rp.data\n",
    "    df_rp = df_rp[['Year', 'Month', 'Deal ID', 'Stage', 'Weight', 'Actuals', 'Leads UW', 'Region']]\n",
    "#     df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_rp = df_rp.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_rp = df_rp.rename(columns={\"Stage\": \"Stages\"})\n",
    "    df_rp = df_rp.rename(columns={\"Weight\": \"Weights\"})\n",
    "    df_rp = df_rp.rename(columns={\"Region\": \"region\"})\n",
    "    df_all = df_rp.merge(df_pdsync_rt.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    df_all['Actuals'] = df_all['Actuals'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'Actuals','dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'industry', \n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "      'dealid',                    \n",
    "      'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#     #  'Practice',\n",
    "#     #  'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#     #  'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "#     result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "#     result = result.rename(columns={\"region\": \"Region\"})\n",
    "#     result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    train = result.drop(columns=['dealid'])\n",
    "    train = train[['Weights', 'dealvalue','Actuals', 'Leads UW', 'Stages', 'region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    \n",
    "    display('Displaying formatted training file below: ')\n",
    "    display(train)\n",
    "    display(create_download_link_l0_train(train))\n",
    "    df_rt = get_test_rt.data\n",
    "    df_rt = df_rt[['Year', 'Month', 'Deal ID', 'Weights', 'Stages', 'Leads UW']]\n",
    "    df_rt = df_rt.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "#     df_rt = df_rt.rename(columns={\"Region\": \"region\"})\n",
    "    df_pdsync_test = get_pdsync_rt.data\n",
    "    df_pdsync_test = df_pdsync_test[['dealid', 'dealvalue','industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact', 'region']]\n",
    "   \n",
    "    df_test = df_rt.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_test['Leads UW'] = df_test['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_test['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_test = df_test[~dropstage]\n",
    "    df_test = df_test[['Year', 'Month', 'dealid', 'Leads UW','dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'industry', \n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    dealvalue_eval_test = df_test.loc[df_test['dealvalue'].apply(lessthanzero)]\n",
    "    df_test = df_test[~df_test.dealvalue.isin(dealvalue_eval_test.dealvalue)]\n",
    "    cols2_test = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_test[cols2_test] = df_test[cols2_test].astype(str)\n",
    "    label_encode_columns_test = df_test[cols2_test].apply(LabelEncoder().fit_transform)\n",
    "    cols1_test = df_test.select_dtypes([np.number]).columns\n",
    "    numerical_test = df_test[cols1_test]\n",
    "    numerical_test['tmp'] = 1\n",
    "    label_encode_columns_test['tmp'] = 1\n",
    "    result_test = pd.concat([numerical_test, label_encode_columns_test], axis=1)\n",
    "    result_test = result_test.drop(columns=['tmp'])\n",
    "    result_test['Date'] = pd.to_datetime(result_test[['Year', 'Month']].assign(DAY=1))\n",
    "    result_test = result_test.drop(columns=['Year','Month'])\n",
    "    result_test = result_test[['Date',\n",
    "      'dealid',                    \n",
    "#       'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#     #  'Practice',\n",
    "#     #  'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#     #  'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result_test['Date'] = pd.to_datetime(result_test['Date'])\n",
    "    result_test = result_test.set_index(result_test['Date'])\n",
    "    result_test = result_test.sort_index()\n",
    "    result_test = result_test.drop(columns=['Date'])\n",
    "\n",
    "    result_test = result_test.drop(columns=['dealid'])\n",
    "    result_test['Actuals'] = np.nan\n",
    "    result_test= result_test[['Weights', 'dealvalue', 'Actuals','Leads UW', 'Stages', 'region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "\n",
    "    display('Displaying formatted testing file below: ')\n",
    "    display(result_test)\n",
    "    display(create_download_link_l0_test(result_test))\n",
    "    x_train = train[[\n",
    "     'Weights',\n",
    "     'dealvalue',\n",
    "     'Leads UW',\n",
    "     'Stages',\n",
    "     'region',\n",
    "     'industry',\n",
    "     'billingtype',\n",
    "     'solcategory',\n",
    "     'projectType',\n",
    "     'businessimpact'\n",
    "    ]]\n",
    "    y_train = train[['Actuals']]\n",
    "    x_test = result_test[[\n",
    "     'Weights',\n",
    "     'dealvalue',\n",
    "     'Leads UW',\n",
    "     'Stages',\n",
    "     'region',\n",
    "     'industry',\n",
    "     'billingtype',\n",
    "     'solcategory',\n",
    "     'projectType',\n",
    "     'businessimpact'\n",
    "    ]]\n",
    "\n",
    "    y_test = result_test[['Actuals']]\n",
    "    \n",
    "    model = XGBRegressor(learning_rate =  0.1, n_estimators=100, colsample_bytree=0.5,max_depth=1)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    pred_sum = y_pred.sum()\n",
    "    text2 = 'Running Predictions for L0'\n",
    "    l0pred = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{text2}</b>\")\n",
    "    display(l0pred)\n",
    "    month = df_rt['Month'].iloc[1]\n",
    "    year = df_rt['Year'].iloc[1]\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\\n\\n\")\n",
    "    time.sleep(5)\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    display(pred_sum)\n",
    "    rmse_val = rmse(np.array(y_pred), np.array(y_test))\n",
    "    print(\"\\nTest rmse error is: \" + str(rmse_val))\n",
    "    rmse_val = rmse(np.array(y_pred), np.array(y_train))\n",
    "    print(\"\\nTrain rmse error is: \" + str(rmse_val))\n",
    "    \n",
    "    y_true = y_test.sum()\n",
    "    y_true, pred_sum = np.array(y_true), np.array(pred_sum)\n",
    "    mape =  np.mean(np.abs((y_true - pred_sum) / y_true)) * 100\n",
    "    \n",
    "    mae =  np.mean(np.abs((y_true - pred_sum) / y_true))\n",
    "    print(\"\\nMAPE is: \"+str(mape))\n",
    "    print(\"\\nMAE is: \"+str(mae))\n",
    "    df_l0_rt = pd.DataFrame(data = [[month,year,pred_sum,'nan',mae,mape]], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l0_rt_final(df_l0_rt))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "text3 = 'Select dates for retraining'\n",
    "retrainlabel = widgets.HTML(value = f\"<b><font size=4>{text3}</b>\")\n",
    "\n",
    "start_date = widgets.DatePicker(\n",
    "    description='Start Date'\n",
    ")\n",
    "end_date = widgets.DatePicker(\n",
    "       description='End Date'\n",
    ")\n",
    "text4 = 'Pick start date for training'\n",
    "pickdates = widgets.HTML(value = f\"<b><font size=2>{text4}</b>\")\n",
    "startend= widgets.Label(\"Start and end dates are from 1st to 1st, for example if training set contains data from Aug '2020 to Oct'2021 then start date will be 01-08-2021 and end date will be 01-11-2021 (1st Nov).\")\n",
    "lastdate= widgets.Label(\"The last date of the dataset in this case 31st october will also be included.\")\n",
    "text5 = 'Pick end date for training'\n",
    "testingdate = widgets.HTML(value = f\"<b><font size=2>{text5}</b>\")\n",
    "\n",
    "text6 = 'Select level of training/testing'\n",
    "levlab = widgets.HTML(value = f\"<b><font size=4>{text6}</b>\")\n",
    "\n",
    "text7 = 'Select prediction method'\n",
    "predlab = widgets.HTML(value = f\"<b><font size=4>{text7}</b>\")\n",
    "def evaluate(button):\n",
    "    with output_box:\n",
    "        selection = dataset_selector.get_interact_value()\n",
    "\n",
    "        if (selection == \"Predict with existing model\"):\n",
    "    #         existingdata.observe(on_change)\n",
    "            get_pdsync_test_button.on_click(get_pdsync_test)\n",
    "            get_test_button.on_click(get_test)\n",
    "            lev_button.on_click(selectlevel)\n",
    "            left_box_lev = widgets.VBox([level_selector, lev_button])\n",
    "            left_box1=widgets.HBox([uploader_pdsync_test,get_pdsync_test_button])\n",
    "            left_box2=widgets.HBox([uploader_test,get_test_button])\n",
    "            left_box_test=widgets.VBox([label_pdsync_test,left_box1, label_test, left_box2,  levlab, left_box_lev])\n",
    "            with output_box:\n",
    "                    display(left_box_test) \n",
    "                               \n",
    "        elif (selection == \"Re-train model\"):\n",
    "            get_pdsync_rt_button.on_click(get_pdsync_rt)\n",
    "            get_rp_button.on_click(get_rp)\n",
    "            get_rt_button.on_click(get_test_rt)\n",
    "            lev_button_rt.on_click(selectlevel_rt)\n",
    "#             date_button.on_click(date_formatter)\n",
    "            left_box_date_l0_start = widgets.VBox([start_date])\n",
    "            left_box_date_l0_end = widgets.VBox([end_date])\n",
    "            left_box3=widgets.HBox([uploader_pdsync_rt,get_pdsync_rt_button])\n",
    "            left_box4=widgets.HBox([uploader_rp,get_rp_button])\n",
    "            left_box5=widgets.HBox([uploader_test_rt,get_rt_button])\n",
    "            left_box_lev_rt = widgets.VBox([level_selector_rt, lev_button_rt])\n",
    "#             left_box_date = widgets.VBox([date_button])\n",
    "            left_box_retrain=widgets.VBox([label_pdsync_rt,left_box3, label_rp,left_box4,label_test_rt, left_box5,retrainlabel, startend, lastdate, pickdates, start_date, testingdate, end_date,levlab, left_box_lev_rt])\n",
    "            with output_box:\n",
    "                    display(left_box_retrain)\n",
    "#                     display(date_formatter())\n",
    "                    \n",
    "\n",
    "\n",
    "my_button = widgets.Button(\n",
    "     description='Next',\n",
    "     disabled=False,\n",
    "     button_style='info', \n",
    "     tooltip='Run'\n",
    "# #     icon='play'\n",
    ")\n",
    "# output_box = widgets.Output()\n",
    "# # display(my_button, output_box)\n",
    "my_button.on_click(evaluate)\n",
    "left_box = widgets.VBox([predlab, dataset_selector, my_button,output_box])\n",
    "widgets.HBox([left_box])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alabaster==0.7.12\n",
      "anaconda-client==1.7.2\n",
      "anaconda-navigator==1.10.0\n",
      "anaconda-project==0.8.3\n",
      "anyio==3.3.1\n",
      "argh==0.26.2\n",
      "argon2-cffi @ file:///C:/ci/argon2-cffi_1596828585465/work\n",
      "asn1crypto @ file:///tmp/build/80754af9/asn1crypto_1596577642040/work\n",
      "astroid @ file:///C:/ci/astroid_1592487315634/work\n",
      "astropy==4.0.2\n",
      "async-generator==1.10\n",
      "atomicwrites==1.4.0\n",
      "attrs @ file:///tmp/build/80754af9/attrs_1604765588209/work\n",
      "autopep8 @ file:///tmp/build/80754af9/autopep8_1596578164842/work\n",
      "Babel @ file:///tmp/build/80754af9/babel_1605108370292/work\n",
      "backcall==0.2.0\n",
      "backports.functools-lru-cache==1.6.1\n",
      "backports.shutil-get-terminal-size==1.0.0\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt @ file:///C:/ci/bcrypt_1597936263757/work\n",
      "beautifulsoup4 @ file:///tmp/build/80754af9/beautifulsoup4_1601924105527/work\n",
      "bitarray @ file:///C:/ci/bitarray_1605065210072/work\n",
      "bkcharts==0.2\n",
      "bleach @ file:///tmp/build/80754af9/bleach_1600439572647/work\n",
      "bokeh @ file:///C:/ci/bokeh_1603297934731/work\n",
      "boto==2.49.0\n",
      "Bottleneck==1.3.2\n",
      "brotlipy==0.7.0\n",
      "certifi==2020.6.20\n",
      "cffi @ file:///C:/ci/cffi_1600699246375/work\n",
      "chardet==3.0.4\n",
      "click==7.1.2\n",
      "cloudpickle @ file:///tmp/build/80754af9/cloudpickle_1598884132938/work\n",
      "clyent==1.2.2\n",
      "colorama @ file:///tmp/build/80754af9/colorama_1603211150991/work\n",
      "comtypes==1.1.7\n",
      "conda==4.9.2\n",
      "conda-build==3.20.5\n",
      "conda-package-handling @ file:///C:/ci/conda-package-handling_1603003327818/work\n",
      "conda-verify==3.4.2\n",
      "contextlib2==0.6.0.post1\n",
      "cryptography @ file:///C:/ci/cryptography_1601046905460/work\n",
      "cycler==0.10.0\n",
      "Cython @ file:///C:/ci/cython_1594829190914/work\n",
      "cytoolz==0.11.0\n",
      "dask @ file:///tmp/build/80754af9/dask-core_1602083700509/work\n",
      "decorator==4.4.2\n",
      "defusedxml==0.6.0\n",
      "diff-match-patch @ file:///tmp/build/80754af9/diff-match-patch_1594828741838/work\n",
      "distributed @ file:///C:/ci/distributed_1605066635297/work\n",
      "docutils==0.16\n",
      "entrypoints==0.3\n",
      "et-xmlfile==1.0.1\n",
      "fastcache==1.1.0\n",
      "filelock==3.0.12\n",
      "flake8 @ file:///tmp/build/80754af9/flake8_1601911421857/work\n",
      "Flask==1.1.2\n",
      "fsspec @ file:///tmp/build/80754af9/fsspec_1602684995936/work\n",
      "future==0.18.2\n",
      "gevent @ file:///C:/ci/gevent_1601397627942/work\n",
      "glob2==0.7\n",
      "greenlet @ file:///C:/ci/greenlet_1600885448389/work\n",
      "h5py==2.10.0\n",
      "HeapDict==1.0.1\n",
      "html5lib @ file:///tmp/build/80754af9/html5lib_1593446221756/work\n",
      "idna @ file:///tmp/build/80754af9/idna_1593446292537/work\n",
      "imageio @ file:///tmp/build/80754af9/imageio_1594161405741/work\n",
      "imagesize==1.2.0\n",
      "importlib-metadata @ file:///tmp/build/80754af9/importlib-metadata_1602276842396/work\n",
      "iniconfig @ file:///tmp/build/80754af9/iniconfig_1602780191262/work\n",
      "intervaltree @ file:///tmp/build/80754af9/intervaltree_1598376443606/work\n",
      "ipykernel @ file:///C:/ci/ipykernel_1596190155316/work/dist/ipykernel-5.3.4-py3-none-any.whl\n",
      "ipython @ file:///C:/ci/ipython_1604083276484/work\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets @ file:///tmp/build/80754af9/ipywidgets_1601490159889/work\n",
      "isort @ file:///tmp/build/80754af9/isort_1602603989581/work\n",
      "itsdangerous==1.1.0\n",
      "jdcal==1.4.1\n",
      "jedi @ file:///C:/ci/jedi_1592833825077/work\n",
      "Jinja2==2.11.2\n",
      "joblib @ file:///tmp/build/80754af9/joblib_1601912903842/work\n",
      "json5==0.9.5\n",
      "jsonschema @ file:///tmp/build/80754af9/jsonschema_1602607155483/work\n",
      "jupyter==1.0.0\n",
      "jupyter-client @ file:///tmp/build/80754af9/jupyter_client_1601311786391/work\n",
      "jupyter-console @ file:///tmp/build/80754af9/jupyter_console_1598884538475/work\n",
      "jupyter-core==4.6.3\n",
      "jupyter-dashboards==0.7.0\n",
      "jupyter-server==1.11.0\n",
      "jupyterlab==2.2.6\n",
      "jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\n",
      "jupyterlab-server @ file:///tmp/build/80754af9/jupyterlab_server_1594164409481/work\n",
      "keyring @ file:///C:/ci/keyring_1601489747083/work\n",
      "kiwisolver @ file:///C:/ci/kiwisolver_1604014703538/work\n",
      "lazy-object-proxy==1.4.3\n",
      "libarchive-c==2.9\n",
      "llvmlite==0.34.0\n",
      "locket==0.2.0\n",
      "lxml @ file:///C:/ci/lxml_1603216366346/work\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib @ file:///C:/ci/matplotlib-base_1603355780617/work\n",
      "mccabe==0.6.1\n",
      "menuinst==1.4.16\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.2.0\n",
      "mkl-random==1.1.1\n",
      "mkl-service==2.3.0\n",
      "mock==4.0.2\n",
      "more-itertools @ file:///tmp/build/80754af9/more-itertools_1605111547926/work\n",
      "mpmath==1.1.0\n",
      "msgpack==1.0.0\n",
      "multipledispatch==0.6.0\n",
      "navigator-updater==0.2.1\n",
      "nbclient @ file:///tmp/build/80754af9/nbclient_1602783176460/work\n",
      "nbconvert @ file:///C:/ci/nbconvert_1601914925608/work\n",
      "nbformat @ file:///tmp/build/80754af9/nbformat_1602783287752/work\n",
      "nest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1605115881283/work\n",
      "networkx @ file:///tmp/build/80754af9/networkx_1598376031484/work\n",
      "nltk @ file:///tmp/build/80754af9/nltk_1592496090529/work\n",
      "nose==1.3.7\n",
      "notebook @ file:///C:/ci/notebook_1601501643625/work\n",
      "numba==0.51.2\n",
      "numexpr==2.7.1\n",
      "numpy @ file:///C:/ci/numpy_and_numpy_base_1603466732592/work\n",
      "numpydoc @ file:///tmp/build/80754af9/numpydoc_1605117425582/work\n",
      "olefile==0.46\n",
      "openpyxl @ file:///tmp/build/80754af9/openpyxl_1598113097404/work\n",
      "packaging==20.4\n",
      "pandas @ file:///C:/ci/pandas_1602083338010/work\n",
      "pandocfilters @ file:///C:/ci/pandocfilters_1605102497129/work\n",
      "paramiko @ file:///tmp/build/80754af9/paramiko_1598886428689/work\n",
      "parso==0.7.0\n",
      "partd==1.1.0\n",
      "path @ file:///C:/ci/path_1598358556930/work\n",
      "pathlib2==2.3.5\n",
      "pathtools==0.1.2\n",
      "patsy==0.5.1\n",
      "pep8==1.7.1\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow @ file:///C:/ci/pillow_1603823068645/work\n",
      "pkginfo==1.6.1\n",
      "pluggy==0.13.1\n",
      "ply==3.11\n",
      "prometheus-client==0.8.0\n",
      "prompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1602688806899/work\n",
      "psutil @ file:///C:/ci/psutil_1598370330503/work\n",
      "py @ file:///tmp/build/80754af9/py_1593446248552/work\n",
      "pycodestyle==2.6.0\n",
      "pycosat==0.6.3\n",
      "pycparser @ file:///tmp/build/80754af9/pycparser_1594388511720/work\n",
      "pycurl==7.43.0.6\n",
      "pydocstyle @ file:///tmp/build/80754af9/pydocstyle_1598885001695/work\n",
      "pyflakes==2.2.0\n",
      "Pygments @ file:///tmp/build/80754af9/pygments_1604103097372/work\n",
      "pylint @ file:///C:/ci/pylint_1598617153160/work\n",
      "PyNaCl @ file:///C:/ci/pynacl_1595000047588/work\n",
      "pyodbc===4.0.0-unsupported\n",
      "pyOpenSSL @ file:///tmp/build/80754af9/pyopenssl_1594392929924/work\n",
      "pyparsing==2.4.7\n",
      "pyreadline==2.1\n",
      "pyrsistent @ file:///C:/ci/pyrsistent_1600141795814/work\n",
      "PySocks==1.7.1\n",
      "pytest==0.0.0\n",
      "python-dateutil==2.8.1\n",
      "python-jsonrpc-server @ file:///tmp/build/80754af9/python-jsonrpc-server_1600278539111/work\n",
      "python-language-server @ file:///tmp/build/80754af9/python-language-server_1600454544709/work\n",
      "pytz==2020.1\n",
      "PyWavelets @ file:///C:/ci/pywavelets_1601658407916/work\n",
      "pywin32==227\n",
      "pywin32-ctypes==0.2.0\n",
      "pywinpty==0.5.7\n",
      "PyYAML==5.3.1\n",
      "pyzmq==19.0.2\n",
      "QDarkStyle==2.8.1\n",
      "QtAwesome @ file:///tmp/build/80754af9/qtawesome_1602272867890/work\n",
      "qtconsole @ file:///tmp/build/80754af9/qtconsole_1600870028330/work\n",
      "QtPy==1.9.0\n",
      "regex @ file:///C:/ci/regex_1602770567298/work\n",
      "requests @ file:///tmp/build/80754af9/requests_1592841827918/work\n",
      "requests-unixsocket==0.2.0\n",
      "rope @ file:///tmp/build/80754af9/rope_1602264064449/work\n",
      "Rtree==0.9.4\n",
      "ruamel-yaml==0.15.87\n",
      "scikit-image==0.17.2\n",
      "scikit-learn @ file:///C:/ci/scikit-learn_1598377018496/work\n",
      "scipy @ file:///C:/ci/scipy_1604596260408/work\n",
      "seaborn @ file:///tmp/build/80754af9/seaborn_1600553570093/work\n",
      "Send2Trash==1.5.0\n",
      "simplegeneric==0.8.1\n",
      "singledispatch @ file:///tmp/build/80754af9/singledispatch_1602523705405/work\n",
      "sip==4.19.13\n",
      "six @ file:///C:/ci/six_1605187374963/work\n",
      "sniffio==1.2.0\n",
      "snowballstemmer==2.0.0\n",
      "sortedcollections==1.2.1\n",
      "sortedcontainers==2.2.2\n",
      "soupsieve==2.0.1\n",
      "Sphinx @ file:///tmp/build/80754af9/sphinx_1597428793432/work\n",
      "sphinxcontrib-applehelp==1.0.2\n",
      "sphinxcontrib-devhelp==1.0.2\n",
      "sphinxcontrib-htmlhelp==1.0.3\n",
      "sphinxcontrib-jsmath==1.0.1\n",
      "sphinxcontrib-qthelp==1.0.3\n",
      "sphinxcontrib-serializinghtml==1.1.4\n",
      "sphinxcontrib-websupport @ file:///tmp/build/80754af9/sphinxcontrib-websupport_1597081412696/work\n",
      "spyder @ file:///C:/ci/spyder_1599054115447/work\n",
      "spyder-kernels @ file:///C:/ci/spyder-kernels_1599051709837/work\n",
      "SQLAlchemy @ file:///C:/ci/sqlalchemy_1603818908746/work\n",
      "statsmodels==0.12.0\n",
      "sympy @ file:///C:/ci/sympy_1605101511098/work\n",
      "tables==3.6.1\n",
      "tblib @ file:///tmp/build/80754af9/tblib_1597928476713/work\n",
      "terminado==0.9.1\n",
      "testpath==0.4.4\n",
      "threadpoolctl @ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "tifffile==2020.10.1\n",
      "toml @ file:///tmp/build/80754af9/toml_1592853716807/work\n",
      "toolz @ file:///tmp/build/80754af9/toolz_1601054250827/work\n",
      "tornado==6.1\n",
      "tqdm @ file:///tmp/build/80754af9/tqdm_1602185206534/work\n",
      "traitlets @ file:///tmp/build/80754af9/traitlets_1602787416690/work\n",
      "typing-extensions @ file:///tmp/build/80754af9/typing_extensions_1598376058250/work\n",
      "ujson @ file:///C:/ci/ujson_1602505266082/work\n",
      "unicodecsv==0.14.1\n",
      "urllib3 @ file:///tmp/build/80754af9/urllib3_1603305693037/work\n",
      "voila==0.2.12\n",
      "watchdog @ file:///C:/ci/watchdog_1593447437088/work\n",
      "wcwidth @ file:///tmp/build/80754af9/wcwidth_1593447189090/work\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.2.1\n",
      "Werkzeug==1.0.1\n",
      "widgetsnbextension==3.5.1\n",
      "win-inet-pton==1.1.0\n",
      "win-unicode-console==0.5\n",
      "wincertstore==0.2\n",
      "wrapt==1.11.2\n",
      "xgboost==0.90\n",
      "xlrd==1.2.0\n",
      "XlsxWriter @ file:///tmp/build/80754af9/xlsxwriter_1602692860603/work\n",
      "xlwings==0.20.8\n",
      "xlwt==1.3.0\n",
      "xmltodict==0.12.0\n",
      "yapf @ file:///tmp/build/80754af9/yapf_1593528177422/work\n",
      "zict==2.0.0\n",
      "zipp @ file:///tmp/build/80754af9/zipp_1604001098328/work\n",
      "zope.event==4.5.0\n",
      "zope.interface @ file:///C:/ci/zope.interface_1602002494740/work\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
